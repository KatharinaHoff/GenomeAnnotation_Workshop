{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed52c95-07b9-4410-9897-39c1360e3fb5",
   "metadata": {},
   "source": [
    "# Genome Annotation\n",
    "\n",
    "Materials for the Genome Annotation a BRAKER & TSEBRA Genome Annotation workshop by Katharina Hoff (katharina.hoff@uni-greifswald.de).\n",
    "\n",
    "In the following, we will walk through the process of genome annotation on the example of a small proportion of the *Arabidopsis thaliana* genome.\n",
    "\n",
    "Runtime estimates are currently not from AWS but from 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz measured with 8 threads. Compute time on AWS should be shorter, even with 4 threads.\n",
    "\n",
    "I was asked to label \"important\" and \"optional\" parts of this notebook for didactic purposes. Please be aware that the second notebook builds on the full contents of this notebook. If you skip something, you may be unable to complete a randomly selected task from the second notebook, or you may have to go back to this one. However, in practice, there are some parts that are more important than others. I will use the following labels:\n",
    "\n",
    "  - â›µ - for smooth sailing in the future, do not skip this\n",
    "  - ðŸš£ - you can skip this, but you may have to go back\n",
    "\n",
    "## â›µ Repeat masking\n",
    "\n",
    "Repetitive sequences are a huge problem for genome annotation. Some repeats only coincidentally look like protein-coding genes, others (such as transposases) are protein-coding genes, but we usually are not interested in any of these \"repeat genes\" when trying to find protein-coding genes in a novel genome. Thus, a genome should be repeat-masked prior gene prediction. \n",
    "\n",
    "Repeat masking is a resource and time-consuming step that is out of scope for this workshop. We recommend using RepeatModeler2 ([paper](https://doi.org/10.1073/pnas.1921046117), [software](https://www.repeatmasker.org/RepeatModeler/) ) to construct a species-specific repeat library and mask the genome with RepeatMasker (ideally, you will perform these computations on a node with >70 threads, in a place with very fast storage i/o, possibly using RAM instead of actual hard drive as a temporary file storage place):\n",
    "\n",
    "```\n",
    "T=72 # you need a large number of threads and fast i/o storage\n",
    "GENOME=/opt/BRAKER/example/genome.fa\n",
    "DB=some_db_name_that_fits_to_species\n",
    "\n",
    "BuildDatabase -name ${DB} ${GENOME}\n",
    "RepeatModeler -database ${DB} -pa ${T} -LTRStruct\n",
    "RepeatMasker -pa 72 -lib ${DB}-families.fa -xsmall ${GENOME}\n",
    "```\n",
    "\n",
    "This results in a file `${GENOME}.masked`. \n",
    "\n",
    "<details>\n",
    "  <summary><b>ðŸš£ Click to learn how to mask more rigorously when needed</b></summary>\n",
    "Depending on the kind of genome, plenty of unmasked repeats may still persist. This is generally an issue to be expected in large genomes, such as vertebrate genomes, and you will notice the problem if the count of predicted proteins is extremely high. You can try to overcome \"under-masking\" with the following steps (we are suggesting to use GNU parallel to speed up the process):\n",
    "\n",
    "```\n",
    "ln -s genome.masked.fa genome.fa\n",
    "splitMfasta.pl --minsize=25000000 ${GENOME}.masked\n",
    "\n",
    "# Running TRF\n",
    "ls genome.split.*.fa | parallel 'trf {} 2 7 7 80 10 50 500 -d -m -h'\n",
    "\n",
    "# Parsing TRF output\n",
    "# The script parseTrfOutput.py is from https://github.com/gatech-genemark/BRAKER2-exp\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat | parallel 'parseTrfOutput.py {} --minCopies 1 --statistics {}.STATS > {}.raw.gff 2> {}.parsedLog'\n",
    "\n",
    "# Sorting parsed output...\"\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff | parallel 'sort -k1,1 -k4,4n -k5,5n {} > {}.sorted 2> {}.sortLog'\n",
    "\n",
    "# Merging gff...\n",
    "FILES=genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff.sorted\n",
    "for f in $FILES\n",
    "do\n",
    "    bedtools merge -i $f | awk 'BEGIN{OFS=\"\\t\"} {print $1,\"trf\",\"repeat\",$2+1,$3,\".\",\".\",\".\",\".\"}' > $f.merged.gff 2> $f.bedtools_merge.log\n",
    "done\n",
    "\n",
    "# Masking FASTA chunk\n",
    "ls genome.split.*.fa | parallel 'bedtools maskfasta -fi {} -bed {}.2.7.7.80.10.50.500.dat.raw.gff.sorted.merged.gff -fo {}.combined.masked -soft &> {}.bedools_mask.log'\n",
    "\n",
    "# Concatenate split genome\n",
    "cat genome.split.*.fa.combined.masked > genome.fa.combined.masked\n",
    "```\n",
    "\n",
    "The file `genome.fa.combined.masked` will be more rigorously masked.\n",
    "</details>\n",
    "\n",
    "## ðŸš£ RNA-Seq alignment with HiSat2\n",
    "\n",
    "Spliced alignments of RNA-Seq short reads are a valuable information source for predicting protein-coding genes with high accuracy.\n",
    "\n",
    "<img src=\"et-rnaseq.png\" alt=\"Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET).\" width=\"600\"/>\n",
    "Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET, <a href=https://doi.org/10.1093/nar/gku55\">Image Source</a>).\n",
    "\n",
    "Executing HiSat2 is out of scope for the current session. You find a readily prepared alignment file in [/opt/BRAKER/example/RNAseq.bam](/opt/BRAKER/example/RNAseq.bam). BRAKER can directly work with FASTQ files, or even with SRA identifiers, but the runtime will be a bit longer, then. For this workshop, we will use the precomputed alignment file to save time.\n",
    "\n",
    "<details>\n",
    "  <summary><b>ðŸš£ If you want to see how such a file was prepared, click here and read.</b></summary>\n",
    "  \n",
    "We will map the *Arabidopsis thaliana* Illumina RNA-Seq reads from library SRR934391 in files [SRR934391_1.fastq.gz](/home/genomics/workshop_materials/genome_annotation/sra/SRR934391_1.fastq.gz) and [SRR934391_2.fastq.gz](/home/genomics/workshop_materials/genome_annotation/sra/SRR934391_2.fastq.gz). These are paired-end data, i.e. one file contains the forward reads while the other contains in the same order the reverse reads. The length of reads is in this case 100 nt.\n",
    "\n",
    "We will use HiSat2 ([publication](https://doi.org/10.1038/s41587-019-0201-4), [software](https://github.com/DaehwanKimLab/hisat2)) to align these reads against a chunk of the *Arabidopsis thaliana* genome contained in the file [genome.fa](genome.fa). (You can in principle use any alignment tool capable of aligning RNA-seq reads to a genome, as long as it can perform spliced alignment.)\n",
    "\n",
    "First, we need to build an index from the genome file:\n",
    "\n",
    "```\n",
    "# building the hisat2 index\n",
    "hisat2-build /opt/BRAKER/example/genome.fa genome-idx 1> hisat2-build.log 2> hisat2-build.err\n",
    "```\n",
    "\n",
    "Inspect the log files [hisat2-build.log](hisat2-build.log) and [hisat2-build.err](hisat2-build.err) for possible errors.\n",
    "\n",
    "Next, we align the RNA-seq reads against the genome. Consider to **not** do this on the Cesky Krumlov Workshop AWS resources. Performing this alignment took about 7 minutes with 70 threads. The precomputed output file is provided at `/home/genomics/workshop_materials/genome_annotation/sra/SRR934391.sam`, and we will continue to use that pre-computed file.\n",
    "\n",
    "```\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR934/SRR934391/SRR934391_1.fastq.gz\n",
    "wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR934/SRR934391/SRR934391_2.fastq.gz\n",
    "\n",
    "RNASEQDIR=.\n",
    "\n",
    "time hisat2 -p ${T} -q -x genome-idx -1 ${RNASEQDIR}/SRR934391_1.fastq.gz \\\n",
    "    -2 ${RNASEQDIR}/SRR934391_2.fastq.gz -S rnaseq.sam \\\n",
    "    1> hisat2-align.log 2> hisat2-align.err\n",
    "```\n",
    "\n",
    "Our goal is to extract information on spliced alignments/intron positons from the alignment output file. To achieve this, we will use a tool called bam2hints that is part of the Augustus software suite ([software](https://github.com/Gaius-Augustus/Augustus)). However, this tool requires a sorted bam-file. Therefore, we first use Samtools ([paper](https://doi.org/10.1093/bioinformatics/btp352), [software](https://github.com/samtools) ) to convert the sam file to bam format:\n",
    "\n",
    "```\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\n",
    "\n",
    "SAMFILE=/home/genomics/workshop_materials/genome_annotation/sra/SRR934391.sam\n",
    "\n",
    "time samtools view -@${T} -bSh ${SAMFILE} -o rnaseq.bam\n",
    "\n",
    "# if you computed your own rnaseq.sam file, delete it to save space on harddrive\n",
    "if [ -f rnaseq.sam ]\n",
    "then\n",
    "    rm rnaseq.sam\n",
    "fi\n",
    "```\n",
    "\n",
    "Then, we sort that bam file (this will require a bit less than 4 GB of RAM):\n",
    "\n",
    "```\n",
    "T=8 # adjust to number of threads that you booted with, takes ~2 minutes with 4 threads\n",
    "\n",
    "time samtools sort -@${T} -n rnaseq.bam -o rnaseq.s.bam\n",
    "\n",
    "# remove the unsorted bam file to save space\n",
    "rm rnaseq.bam\n",
    "```\n",
    "\n",
    "Careful, above bam file is just an demo example! We will be using a different bam file for running BRAKER because the above BAM file does not contain sufficient data for running BRAKER3, successfully!\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf2da9",
   "metadata": {},
   "source": [
    "## â›µ Annotation of protein coding genes\n",
    "\n",
    "Structural genome annotation is ideally performed by a combination of a statistical model (e.g. Hidden Markov Model derivate) and extrinsic evidence (e.g. from transcriptomics or known protein sequences). The statistical model parameters have to be adapted to the genomic properties of novel species. For adapting parameters, an initial set of high-quality training genes from the target species is required. This is tricky to obtain. BRAKER is a perl script that comprises several pipelines to automated the solution of this problem: fully automatically generate an initial set of training genes, train gene finders, and then predict genes with the trained parameters and extrinsic evidence.\n",
    "\n",
    "We will first take an approach to structural genome annotation that takes advantage both of RNA-Seq data, and a large database of known proteins, using BRAKER3 ([poster from PAG2023](https://www.researchgate.net/profile/Lars-Gabriel-3/publication/367409816_The_BRAKER3_Genome_Annotation_Pipeline/links/63d14cbae922c50e99c29c7a/The-BRAKER3-Genome-Annotation-Pipeline.pdf), [software](https://github.com/Gaius-Augustus/BRAKER)). If sufficient transcriptome data is available, then BRAKER3 is usually the best choice of pipeline. However, in the lack of transcriptome data, we need to consider alternative approaches. \n",
    "\n",
    "If transcriptome evidence is available but it just was not sufficient for obtaining good results with BRAKER3, then protein supported gene prediction with BRAKER2 ([paper](https://doi.org/10.1093/nargab/lqaa108)) is often a good option.\n",
    "\n",
    "In the total absence of transcriptome data, we recommend running either BRAKER2 with a large database of proteins, alone, or for larger genomes (such as vertebrates), we recommend the application of GALBA ([preprint](https://www.biorxiv.org/content/10.1101/2023.04.10.536199v1.abstract), [software](https://github.com/Gaius-Augustus/GALBA)) with reference proteomes of a few closely related, already annotated species.\n",
    "\n",
    "For ab initio gene prediction using deep learning, Tiberius ([paper](https://doi.org/10.1093/bioinformatics/btae685), [software](https://github.com/Gaius-Augustus/Tiberius)) provides a modern alternative that does not require species-specific training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64aae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with, takes ~14 minutes with 8 threads\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER3 ]\n",
    "then\n",
    "    rm -rf BRAKER3\n",
    "fi\n",
    "\n",
    "ORTHODB=/opt/BRAKER/example/subsampled_viri.fa # adjust to suitable clade of real OrthoDB from https://bioinf.uni-greifswald.de/bioinf/partitioned_odb11/\n",
    "BUSCOLINEAGE=eukaryota_odb10 # adjust to more suitable lineage for real annotation runs\n",
    "\n",
    "# run BRAKER3\n",
    "time braker.pl --workingdir=BRAKER3 --genome=/opt/BRAKER/example/genome.fa \\\n",
    "    --bam=/opt/BRAKER/example/RNAseq.bam \\\n",
    "    --prot_seq=${ORTHODB} --busco_lineage=${BUSCOLINEAGE} --threads ${T} \\\n",
    "    --gm_max_intergenic 10000 --skipOptimize # remember to remove both these options for real jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37295089",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Out of time, job died? Click here.</b></summary>\n",
    "If you ran out of time (the BRAKER3 job takes substantial time), you may copy the most important files as follows from a notebook cell:\n",
    "\n",
    "```\n",
    "%%script bash\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER3 ]\n",
    "then\n",
    "    rm -rf BRAKER3\n",
    "fi\n",
    "cp -r BRAKER3_precomputed_results BRAKER3\n",
    "```\n",
    "</details>\n",
    "\n",
    "Let's inspect the output, the most important files are braker.gtf, Augustus/augustus.hints.gtf, and GeneMark-ETP/genemark.gtf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4444062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "cd BRAKER3\n",
    "ls -lh braker.gtf Augustus/augustus.hints.gtf GeneMark-ETP/genemark.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ff890",
   "metadata": {},
   "source": [
    "The file [BRAKER3/what-to-cite.txt](BRAKER3/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER3.\n",
    "\n",
    "braker.gtf is the main output. BRAKER internally runs compleasm to pick the best gene set according to BUSCO presence. Be aware of this when generating the following BUSCO plot for quality control. (The folder braker_original contains BRAKER predictions prior adding BUSCOs with compleasm in case you want to look at these.)\n",
    "\n",
    "Before running BUSCO, we need to make sure that we have protein sequences of all three gene sets (only the braker.aa exists by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "# generate protein (and coding seq file) from AUGUSTUS predictions\n",
    "cd BRAKER3/Augustus\n",
    "getAnnoFastaFromJoingenes.py -g /opt/BRAKER/example/genome.fa -o augustus.hints -f augustus.hints.gtf\n",
    "# generate protein (and coding seq file) from GeneMark-ETP predictions\n",
    "cd ../GeneMark-ETP\n",
    "getAnnoFastaFromJoingenes.py -g /opt/BRAKER/example/genome.fa -o genemark -f genemark.gtf\n",
    "# see file sizes\n",
    "cd ../\n",
    "ls -lh braker.aa GeneMark-ETP/genemark.aa Augustus/augustus.hints.aa\n",
    "# Count number of transcripts by counting FASTA headers\n",
    "echo \"Counting number of protein sequences = transcripts\"\n",
    "grep -c \">\" braker.aa GeneMark-ETP/genemark.aa Augustus/augustus.hints.aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee189b",
   "metadata": {},
   "source": [
    "GALBA has a simple script to compute the ratio of mono- to multi-exonic genes (only counting one isoform if one gene has several alternative isoforms, that's why the transcript number differs from the number above for methods that contain alternative transcripts, such as AUGUSTUS and BRAKER):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "cd BRAKER3\n",
    "echo \"Computing some descriptive statistics for BRAKER:\"\n",
    "analyze_exons.py -f braker.gtf\n",
    "echo \"\"\n",
    "echo \"Doing the same for Augustus:\"\n",
    "analyze_exons.py -f Augustus/augustus.hints.gtf\n",
    "echo \"\"\n",
    "echo \"And for GeneMark-ETP:\"\n",
    "analyze_exons.py -f GeneMark-ETP/genemark.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1cedd",
   "metadata": {},
   "source": [
    "#### â›µ BUSCO assessment\n",
    "\n",
    "BUSCO ([paper](https://doi.org/10.1002/cpz1.323), [software](https://gitlab.com/ezlab/busco)) can provide information on sensitivity with respect to a clade-specific core gene set. We will in the following use BUSCO to compare sensitivity in the BRAKER3, AUGUSTUS, GeneMark-ETP, and Tiberius gene sets.\n",
    "\n",
    "First, we find the closest BUSCO lineage (we are working on *Arabidopsis thaliana*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6117f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "busco --list-datasets > busco_lineages.txt 2> busco_lineages.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e452c",
   "metadata": {},
   "source": [
    "All available lineages are now in [busco_lineages.txt](busco_lineages.txt). (Check [busco_lineages.log](busco_lineages.log) for possible errors.)\n",
    "\n",
    "Check at [NCBI taxonomy](https://www.ncbi.nlm.nih.gov/taxonomy) the lineage of the target *Arabidopsis*. I believe the lineage is:\n",
    "\n",
    "`cellular organisms; Eukaryota; Viridiplantae; Streptophyta; Streptophytina; Embryophyta; Tracheophyta; Euphyllophyta; Spermatophyta; Magnoliopsida; Mesangiospermae; eudicotyledons; Gunneridae; Pentapetalae; rosids; malvids; Brassicales; Brassicaceae; Camelineae`\n",
    "\n",
    "Now find a related lineage in [busco_lineages.txt](busco_lineages.txt). `brassicales_odb10` is the closest lineage. (If we had not wanted to save time when running BRAKER, we would also have used this lineage for the BRAKER run.)\n",
    "\n",
    "Next, we run a BUSCO assessment on all gene sets (this takes ~4 minutes with 8 threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e868f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "cd BRAKER3\n",
    "# create links if not already present\n",
    "if [ ! -L augustus.aa ]\n",
    "then\n",
    "    ln -s Augustus/augustus.hints.aa augustus.aa\n",
    "    sleep 1 # not sure why we need to wait a few seconds, but otherwise system doesn't find the file\n",
    "fi\n",
    "\n",
    "if [ ! -L genemark.aa ]\n",
    "then\n",
    "    ln -s GeneMark-ETP/genemark.aa genemark.aa\n",
    "    sleep 1 # not sure why we need to wait a few seconds, but otherwise system doesn't find the file\n",
    "fi\n",
    "\n",
    "if [ ! -L tiberius.aa ]\n",
    "then\n",
    "    ln -s ../Tiberius/tiberius.aa tiberius.aa\n",
    "    sleep 1\n",
    "fi\n",
    "\n",
    "if [ ! -d busco_downloads ]\n",
    "then\n",
    "    mkdir busco_downloads\n",
    "    cd busco_downloads\n",
    "    ln -s /home/genomics/workshop_materials/genome_annotation/busco/brassicales_odb10 brassicales_odb10\n",
    "    cd ..\n",
    "fi\n",
    "\n",
    "GENESETS=(braker augustus genemark tiberius)\n",
    "\n",
    "for g in ${GENESETS[@]}; do\n",
    "    echo \"Processing ${g}...\"\n",
    "    # delete old output if existing\n",
    "    if [ -d busco_${g} ]\n",
    "    then\n",
    "        rm -r busco_${g}\n",
    "    fi\n",
    "    # run BUSCO\n",
    "    busco -m proteins -i ${g}.aa -o busco_${g} \\\n",
    "        -l brassicales_odb10 -c ${T} &> busco_${g}.log\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9260cae",
   "metadata": {},
   "source": [
    "Next, we visualize the BUSCO results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "cd BRAKER3\n",
    "\n",
    "# create BUSCO_summaries folder if not present\n",
    "if ! [ -d BUSCO_summaries ]\n",
    "then\n",
    "    mkdir BUSCO_summaries\n",
    "fi\n",
    "\n",
    "# copy all BUSCO results into the summaries folder\n",
    "cp busco_*/short_summary*.txt BUSCO_summaries\n",
    "\n",
    "# generate BUSCO plot\n",
    "generate_plot.py -wd BUSCO_summaries &> generate_plot.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b770b22",
   "metadata": {},
   "source": [
    "Check the file [generate_plot.log](generate_plot.log) for possible errors. This results in the following figure (stored at [BRAKER3/BUSCO_summaries/busco_figure.png](BRAKER3/BUSCO_summaries/busco_figure.png)):\n",
    "\n",
    "<img src=\"BRAKER3/BUSCO_summaries/busco_figure.png\" alt=\"BUSCO results\" width=\"400\"/>\n",
    "\n",
    "The data that we used in this session was selected purely on the criterion of feasible runtime. In a real scenario, with a complete genome, the BUSCO plot should contain a much larger number of complete BUSCOs, and you are usually happy if the number BUSCOs in the final BRAKER3 gene set is higher or equal to the number of BUSCOs detected in the AUGUSTUS and GeneMark-ETP set, while the total number of transcripts does not grow into an unexpected way (e.g. having 80.000 proteins in a BRAKER gene set does seem odd in most cases...). If the same BUSCO lineage had been chosen for BRAKER and BUSCO, that would also be the case, here (BUSCOs in BRAKER being more complete than in AUGUSTUS).\n",
    "\n",
    "But what can we do if there is no RNA-Seq data for a particular species? In that case, we can resort to using either BRAKER2 (for small and medium sized genomes, with a large database of proteins that might be only remotely related), or we may use GALBA (for large vertebrate genomes, with a few closely related reference proteomes).\n",
    "\n",
    "### â›µ BRAKER2\n",
    "\n",
    "BRAKER2 ([paper](https://doi.org/10.1093/nargab/lqaa108)) uses spliced alignment information from a huge database of proteins against the target genome. We typically use OrthoDB partitions of clades, hosted at https://bioinf.uni-greifswald.de/bioinf/partitioned_odb11/. Note: a set of proteins from one or a few related species is not sufficient for running BRAKER2. A particular set of proteins of a closely related species can be appended to a larger database for running BRAKER2. However, BRAKER2 is not an ideal tool for recovering a complete set of proteins from a related species.\n",
    "\n",
    "The following call of BRAKER2 takes ~14 minutes on 8 threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "ORTHODB=/opt/BRAKER/example/subsampled_viri.fa # adjust to suitable OrthoDB clade, see BRAKER3\n",
    "BUSCOLINEAGE=eukaryota_odb10 # adjust to more suitable lineage for real annotation runs\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER2 ]\n",
    "then\n",
    "    rm -rf BRAKER2\n",
    "fi\n",
    "\n",
    "time braker.pl --workingdir=BRAKER2 --genome=/opt/BRAKER/example/genome.fa --prot_seq=${ORTHODB} \\\n",
    "    --busco_lineage ${BUSCOLINEAGE} --threads ${T} \\\n",
    "    --gm_max_intergenic 10000 --skipOptimize \\ # remember to remove both options if you are running a real job\n",
    "    2> braker2.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff71c1e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Out of time, job died? Click here.</b></summary>\n",
    "If you ran out of time (the BRAKER2 job takes substantial time), you may copy the most important files as follows from a notebook cell:\n",
    "\n",
    "```\n",
    "%%script bash\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER2 ]\n",
    "then\n",
    "    rm -rf BRAKER2\n",
    "fi\n",
    "cp -r BRAKER2_precomputed_results BRAKER2\n",
    "```\n",
    "</details>\n",
    "\n",
    "The most important output files are:\n",
    "\n",
    "   * [BRAKER2/braker.gtf](BRAKER2/braker.gtf) - BRAKER gene predictions\n",
    "   * [BRAKER2/Augustus/augustus.hints.gtf](BRAKER2/Augustus/augustus.hints.gtf) - intermediate AUGUSTUS gene predictions\n",
    "   * [BRAKER2/GeneMark-EP/genemark.gtf](BRAKER2/GeneMark-EP/genemark.gtf) - intermediate GeneMark-EP gene predictions\n",
    "   * [BRAKER2/hintsfile.gff](BRAKER2/hintsfile.gff) - hints that were used for running AUGUSTUS and TSEBRA in BRAKER\n",
    "   \n",
    "The file [BRAKER2/what-to-cite.txt](BRAKER2/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER2. \n",
    "\n",
    "All methods described for BRAKER3 (BUSCO, number of transcripts, mono:mult exon ratio, etc.) are of course applicable to BRAKER2, GALBA, and BRAKER1, as well. We will skip it here because of time constraints.\n",
    "\n",
    "### â›µ GALBA\n",
    "\n",
    "GALBA ([preprint](https://www.biorxiv.org/content/10.1101/2023.04.10.536199v1.abstract), [software](https://github.com/Gaius-Augustus/GALBA)) is a BRAKER-spinoff that uses miniprot ([paper](https://doi.org/10.1093/bioinformatics/btad014), [software](https://github.com/lh3/miniprot)) to generate a training gene set of AUGUSTUS. In contrast to the BRAKER2 and BRAKER3 pipelines, GALBA is not very good at using remotely related protein evidence. However, given reference proteins of several closely related species, GALBA is very good at recovering gene structures, particularly in large vertebrate genomes. You may execute GALBA as follows (using a toy example data set, it executes within a 5 minutes on 8 threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d GALBA ]\n",
    "then\n",
    "    rm -rf GALBA\n",
    "fi\n",
    "\n",
    "time galba.pl --workingdir=GALBA --genome=/opt/BRAKER/example/genome.fa \\\n",
    "    --prot_seq=/opt/GALBA/example/proteins.fa \\\n",
    "    --threads ${T} \\\n",
    "    --skipOptimize \\ # remember to remove this option if you are running a real job\n",
    "    2> galba.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac784782",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Out of time, job died? Click here.</b></summary>\n",
    "It is unlikely that GALBA will note complete, fast. However, you may copy the most important files as follows from a notebook cell:\n",
    "\n",
    "```\n",
    "%%script bash\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d GALBA ]\n",
    "then\n",
    "    rm -rf GALBA\n",
    "fi\n",
    "cp -r GALBA_precomputed_results GALBA\n",
    "```\n",
    "</details>\n",
    "\n",
    "The most important output files are:\n",
    "\n",
    "   * [GALBA/galba.gtf](GALBA/galba.gtf) - gene predictions by GALBA\n",
    "   * [GALBA/hintsfile.gff](GALBA/hintsfile.gff) - hints that were used for running AUGUSTUS in GALBA\n",
    "   \n",
    "The file [GALBA/what-to-cite.txt](GALBA/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with GALBA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300410d-0522-4f4a-9400-88d63eab6e58",
   "metadata": {},
   "source": [
    "### ðŸš£ Tiberius\n",
    "\n",
    "Tiberius ([paper](https://doi.org/10.1093/bioinformatics/btae685), [software](https://github.com/Gaius-Augustus/Tiberius)) is a deep learning-based tool for ab initio gene prediction. Unlike traditional gene finders that require species-specific training, Tiberius uses pre-trained models that can predict genes across a wide range of species without any training data from the target species.\n",
    "\n",
    "Tiberius is particularly useful when:\n",
    "- No RNA-Seq data is available\n",
    "- No closely related protein sequences are available\n",
    "- You want a quick initial annotation to compare against other methods\n",
    "\n",
    "The container includes a conda environment `tiberius_env` with Tiberius installed. Tiberius requires a softmasked genome (lowercase letters for repeats). The model we will use is `eudicotyledons.yaml`, which is suitable for our *Arabidopsis thaliana* example.\n",
    "\n",
    "Let's run Tiberius on our genome (using a toy example data set, it executes within a 1.5 minutes on the CPU; note that Tiberius will be much faster on a GPU if you want to annotate a larger genome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c34fe6-3fb7-443f-a026-2a8bf77d304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 09:34:48.175803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-03 09:34:48.345768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-03 09:34:48.386161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-03 09:34:48.762675: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-03 09:34:50.576753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2026-01-03 09:34:52,684 - Model Config File: /opt/Tiberius/model_cfg/eudicotyledons.yaml\n",
      "2026-01-03 09:34:52,687 - Output file: /home/katharina/git/GenomeAnnotation_Workshop/Tiberius/tiberius.gtf\n",
      "2026-01-03 09:34:52,687 - Batch size: 16\n",
      "2026-01-03 09:34:52,687 - Tile length: 259992\n",
      "2026-01-03 09:34:52,687 - Minimum sequence length: 0\n",
      "2026-01-03 09:34:52,688 - Strand: ['+', '-']\n",
      "2026-01-03 09:34:52,688 - HMM parallel factor: 471\n",
      "2026-01-03 09:34:52,688 - Softmasking: True\n",
      "2026-01-03 09:34:52,688 - Genome sequence path: /opt/BRAKER/example/genome.fa\n",
      "2026-01-03 09:34:52,688 - Warning: No model weights provided, they will be downloaded to /home/katharina/git/GenomeAnnotation_Workshop/eudicotyledons_weights.tar.gz.\n",
      "2026-01-03 09:34:52,688 - Weights for Tiberius model will be downloaded from https://bioinf.uni-greifswald.de/bioinf/tiberius/models/eudicotyledons_weights.tar.gz\n",
      "2026-01-03 09:34:53,307 - Extracting weights to /home/katharina/git/GenomeAnnotation_Workshop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using TensorFlow version 2.17.1, which is newer than the recommended maximum version 2.12. It will produce an error if you use a sequence length > 259,992 during inference!\n",
      "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
      "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
      "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
      "â”‚ input_layer         â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m6\u001b[0m)   â”‚          \u001b[32m0\u001b[0m â”‚ -                 â”‚\n",
      "â”‚ (\u001b[94mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ initial_conv        â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m) â”‚      \u001b[32m2,432\u001b[0m â”‚ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] â”‚\n",
      "â”‚ (\u001b[94mConv1D\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m) â”‚        \u001b[32m256\u001b[0m â”‚ initial_conv[\u001b[32m0\u001b[0m][\u001b[32mâ€¦\u001b[0m â”‚\n",
      "â”‚ (\u001b[94mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ conv_1 (\u001b[94mConv1D\u001b[0m)     â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m) â”‚    \u001b[32m147,584\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m) â”‚        \u001b[32m256\u001b[0m â”‚ conv_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      â”‚\n",
      "â”‚ (\u001b[94mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ conv_2 (\u001b[94mConv1D\u001b[0m)     â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m) â”‚    \u001b[32m147,584\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ concatenate         â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m134\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0mâ€¦ â”‚\n",
      "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ conv_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ R1 (\u001b[94mReshape\u001b[0m)        â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,      â”‚          \u001b[32m0\u001b[0m â”‚ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] â”‚\n",
      "â”‚                     â”‚ \u001b[32m1206\u001b[0m)             â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ pre_lstm_dense      â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m744\u001b[0m) â”‚    \u001b[32m898,008\u001b[0m â”‚ R1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]          â”‚\n",
      "â”‚ (\u001b[94mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ biLSTM_1            â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m744\u001b[0m) â”‚  \u001b[32m3,324,192\u001b[0m â”‚ pre_lstm_dense[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
      "â”‚ (\u001b[94mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ biLSTM_2            â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m744\u001b[0m) â”‚  \u001b[32m3,324,192\u001b[0m â”‚ biLSTM_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
      "â”‚ (\u001b[94mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ dense (\u001b[94mDense\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m270\u001b[0m) â”‚    \u001b[32m201,150\u001b[0m â”‚ biLSTM_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Reshape2 (\u001b[94mReshape\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m30\u001b[0m)  â”‚          \u001b[32m0\u001b[0m â”‚ dense[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]       â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ concatenate_1       â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m158\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ Reshape2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   â”‚\n",
      "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ conv_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ out_dense (\u001b[94mDense\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m15\u001b[0m)  â”‚      \u001b[32m2,385\u001b[0m â”‚ concatenate_1[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ out (\u001b[94mActivation\u001b[0m)    â”‚ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m15\u001b[0m)  â”‚          \u001b[32m0\u001b[0m â”‚ out_dense[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m8,048,039\u001b[0m (30.70 MB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,048,039\u001b[0m (30.70 MB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 09:34:54,256 - Tiberius gene predicton 1/2 \n",
      "2026-01-03 09:35:18,469 - Tiberius gene predicton 2/2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### LSTM prediction\n",
      "LSTM took 0.2673 minutes to execute.\n",
      "### HMM Viterbi\n",
      "HMM took 0.1138 minutes to execute.\n",
      "### LSTM prediction\n",
      "LSTM took 0.2685 minutes to execute.\n",
      "### HMM Viterbi\n",
      "HMM took 0.0864 minutes to execute.\n",
      "Tiberius took 0.7964 minutes to execute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m54.343s\n",
      "user\t8m0.926s\n",
      "sys\t1m39.902s\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d Tiberius ]\n",
    "then\n",
    "    rm -rf Tiberius\n",
    "fi\n",
    "\n",
    "mkdir Tiberius\n",
    "\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "conda activate tiberius_env\n",
    "\n",
    "# Unset matplotlib backend to avoid conflict with Jupyter's inline backend\n",
    "unset MPLBACKEND\n",
    "\n",
    "# Note: --seq_len is required for TensorFlow >= 2.13 (max 259992)\n",
    "time python /opt/Tiberius/tiberius.py --genome /opt/BRAKER/example/genome.fa \\\n",
    "    --out Tiberius/tiberius.gtf \\\n",
    "    --model_cfg /opt/Tiberius/model_cfg/eudicotyledons.yaml \\\n",
    "    --seq_len 259992 \\\n",
    "    --protseq Tiberius/tiberius.aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109df65",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Out of time, job died? Click here.</b></summary>\n",
    "This job should complete relatively quickly, but if needed you can skip this step and continue with the other methods.\n",
    "</details>\n",
    "\n",
    "The most important output files are:\n",
    "\n",
    "   * [Tiberius/tiberius.gtf](Tiberius/tiberius.gtf) - Tiberius gene predictions\n",
    "   * [Tiberius/tiberius.aa](Tiberius/tiberius.aa) - Tiberius protein sequences\n",
    "   \n",
    "Tiberius predictions can be combined with other gene sets using TSEBRA if desired. Note that Tiberius is an *ab initio* predictor, meaning it does not use any extrinsic evidence - it relies solely on the sequence patterns learned during deep learning training. Tiberius is very good at predicting gene structures that are typically supported by extrinsic evidence in other pipelines, such as BRAKER3. However, University of Greifswald Bioinformatics is currently developing new pipeline for integrating extrinsic evidence derived gene models directly with Tiberius genes, stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1502dc",
   "metadata": {},
   "source": [
    "### ðŸš£ TSEBRA\n",
    "\n",
    "TSEBRA is a tool for selecting a highly accurate gene set from several input sets according to supporting extrinsic evidence. BRAKER internally executes TSEBRA to combine the GeneMark and the AUGUSTUS gene set. If all went well, you do not have run TSEBRA, separately, at all. However, one scenario where TSEBRA may be useful, remains:\n",
    "   \n",
    "   * You want to combine gene sets from different annotation pipelines, e.g. BRAKER3 and Tiberius.\n",
    "   \n",
    "We will have a look at how to generally run TSEBRA on the example of merging the BRAKER3 and Tiberius gene sets according to the BRAKER3 evidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d TSEBRA ]\n",
    "then\n",
    "    rm -rf TSEBRA\n",
    "fi\n",
    "\n",
    "mkdir TSEBRA\n",
    "cd TSEBRA\n",
    "tsebra.py -g ../BRAKER3/Augustus/augustus.hints.gtf,../BRAKER3/GeneMark-ETP/genemark.gtf,../Tiberius/tiberius.gtf \\\n",
    "    -e ../BRAKER3/hintsfile.gff -o tsebra.gtf 2> tsebra.log\n",
    "\n",
    "# Generate protein sequences from TSEBRA output\n",
    "getAnnoFastaFromJoingenes.py -g /opt/BRAKER/example/genome.fa -o tsebra -f tsebra.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a724547",
   "metadata": {},
   "source": [
    "Check the file [tsebra.log](TSEBRA/tsebra.log) for possible errors. The final gene set is in file [tsebra.gtf](TSEBRA/tsebra.gtf). The protein sequences are in [tsebra.aa](TSEBRA/tsebra.aa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a551a-5464-4450-9fee-f910798fd844",
   "metadata": {},
   "source": [
    "## â›µ Data visualization in the UCSC Genome Browser\n",
    "\n",
    "Visualization of gene structures in context with extrinsic evidence is essential for coming to a decision on whether a gene set \"makes sense\" or \"does not make sense\". Typical problems that you may observe in a genome browser include \"split genes\" (where evidence implies two genes should in fact be a single gene) or \"joined genes\" (where evidence implies one gene should be split into two genes).\n",
    "\n",
    "The UCSC Genome Browser ([paper](https://doi.org/10.1101/gr.229102), [resource](https://genome.ucsc.edu/)) is one of the most popular genome browsers. It has the advantage that you do not have to install a browser instance on your own webserver. Instead, you only need to provide a certain data structure with your target data on a webserver. The UCSC Genome Browser servers can display your data from there. The data structures are called \"track data hubs\" or \"assembly hubs\" ([paper](https://doi.org/10.1093/bioinformatics/btt637)). \n",
    "\n",
    "MakeHub ([paper](https://doi.org/10.1016/j.gpb.2019.05.003), [software](https://github.com/Gaius-Augustus/MakeHub )) is a python script that fully automates the generation of such track data hubs for novel genomes. In the following, we will generate a simple track data hub for the genome sequence that we annotated with BRAKER3 (takes only a few seconds, simply repeat execution in case it fails the first time due to internet connectivity problems):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "time make_hub.py -e katharina.hoff@uni-greifswald.de \\\n",
    "    --genome /opt/BRAKER/example/genome.fa --long_label \"A chunk from the Arabidopsis thaliana genome\" \\\n",
    "    --short_label at_chunk  --bam /opt/BRAKER/example/RNAseq.bam --threads ${T} \\\n",
    "    --latin_name \"Arabidopsis thaliana\" \\\n",
    "    --assembly_version \"artifically split custom assembly\" \\\n",
    "    --hints BRAKER3/hintsfile.gff --gene_track BRAKER3/braker.gtf BRAKER3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc653250-d5b7-4714-a346-e22563d67bc9",
   "metadata": {},
   "source": [
    "You can't perform the suggested `scp` command from the apphub, unless you have privileges on a University of Greifswald webserver. We have therefore copied a prepared hub in advance. The `hub.txt` is available at https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt . Remember that link.\n",
    "\n",
    "In order to visualize your data, go to https://genome.ucsc.edu/ in **Chrome** (do not use Firefox since it does not seem to work properly with the UCSC Genome Browser at the moment). Click on `My Data` -> `Track Hubs` -> choose the European mirror -> click on `Connected Hubs` and enter the link https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt into the text window -> click on `Add Hub` -> click on `Go`. Congratulations, your Hub is now connected. You should see something like this: \n",
    "\n",
    "<img src=\"at_chunk.png\" alt=\"UCSC Genome Browser example\" width=\"1000\"/>\n",
    "\n",
    "### â›µ How to know which sequences to browse\n",
    "\n",
    "The long sequences are usually the most interesting to look at. The following command gives you the names of sequences in the order of descending length, you can copy-paste the sequence names into the search window in the UCSC Genome Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd61f2-9007-45bd-83bf-5af23fee0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "N=5 # how many longest sequences would you like to know about\n",
    "\n",
    "summarizeACGTcontent.pl /opt/BRAKER/example/genome.fa | grep bases | head -${N} | sort -n \\\n",
    "   | perl -ne 'm/(\\d+)\\s+bases\\.\\s+(\\S+)/; print \"$2\\t$1\\n\";'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7681d88-0284-4819-bf10-955279525239",
   "metadata": {},
   "source": [
    "## ðŸš£ How to run BRAKER (and other software) in Docker\n",
    "\n",
    "If you have a machine on which you have root permissions and Docker, you can run the exact same container as we have been using during this workshop as follows:\n",
    "\n",
    "```\n",
    "sudo docker run --rm -it -u root katharinahoff/bioinformatics-notebook:latest bash\n",
    "```\n",
    "\n",
    "You can execute all shell commands that we covered in this notebook in that container.\n",
    "\n",
    "## ðŸš£ How to run BRAKER, GALBA, MakeHub, etc. in Singularity\n",
    "\n",
    "Please read instructions in the [README.md](README.md) file.\n",
    "\n",
    "## â›µ Troubleshooting\n",
    "\n",
    "### ðŸš£ I have 80.000 genes predicted by BRAKER/TSEBRA in a full genome, what shall I do?\n",
    "\n",
    "Please first check whether you are referring to genes, or to transcripts. BRAKER predicts alternative isoforms. If RNA-Seq data supports this, the number of alternative transcripts may be large, but likely true. If it's really genes that you counted, then 80.000 sounds way too much, indeed (unless you are dealing with a genome that has multiple copies of each chromosome). Most likely, GeneMark-ET/ES/EP/ETP produced highly fragmented training genes for AUGUSTUS. This will also lead to highly fragmented genes predicted by AUGUSTUS. First, check whether your genome has been masked for repeats. Consider using the additional TRF masking desribed at the top of this notebook. If that does not help, and if you have a protein set of closely related species at hand, consider using that protein set as sole training data for AUGUSTUS. You can use GALBA for this (https://github.com/Gaius-Augustus/GALBA).\n",
    "\n",
    "### ðŸš£ I have only 10.000 genes predicted by BRAKER/TSEBRA in a full genome, what shall I do?\n",
    "\n",
    "Check whether the BRAKER output files in subfolders Augustus and GeneMark-* produced more genes than TSEBRA. By default, TSEBRA will discard genes without evidence. If you have only little evidence for your species, TSEBRA might be a bad idea. You can also try rerunning TSEBRA with enforcing one of the gene sets.  There are also species for which is \"normal\" to observe less than 10,000 genes, check the annotated relatives.\n",
    "\n",
    "### ðŸš£ How do I know how many genes to expect?\n",
    "\n",
    "Hard to say. You can download gene sets of related species e.g. from NCBI Genomes, and count. Some gene sets tend to be \"underannotated\", i.e. they may represent rather the lower numbers of what might be realistic. Katharina usually gets nervous about more than 45000 genes and fewer than 15000 genes. These are definitely weird gene counts - but as stated before, there are cases where these are totally fine, too. Otherwise: always inspect your gene set in a Genome Browser such as the UCSC Genome Browser to identify problems.\n",
    "\n",
    "### ðŸš£ I have long isoseq RNA-Seq transcripts, can I put them into BRAKER?\n",
    "\n",
    "Yes, you find a dedicated container and instructions on the poster from PAG 2024 at https://github.com/Gaius-Augustus/BRAKER/blob/master/docs/posters/poster_PAG2024.pdf . Note: this works with only isoseq data, not with mixed short- and long reads. If you have both data types, you could run it once with long reads, once with short reads, and then combine the results with TSEBRA.\n",
    "\n",
    "### ðŸš£ I opened an issue on GitHub about BRAKER or TSEBRA 100 days ago, nobody replied, why?\n",
    "\n",
    "We are a small team of developers. We try our best and usually respond to well described and easy-to-solve issues within a rather short time frame. Solving other issues may take considerable amounts of time that we simply do not have, or they may be described in a way that we don't know what do with them... please be patient with us.\n",
    "\n",
    "### â›µ I have a problem, whom do I tell?\n",
    "\n",
    "Please read through the Issues on Github. If the issue does not exist, yet, open an issue.\n",
    "\n",
    "# â›µ Ready to move on?\n",
    "\n",
    "If you feel confident about your skills, take them to the next level. We have prepared chromosome 4 of a small genome in the following notebook: [Annotate_Babesia_duncani.ipynb](Annotate_Babesia_duncani.ipynb). The task is designed such that you will not complete all tasks during today's session. Instead, you will be randomly assigned with a sub-task, and we will merge the results of everyone who participates to gain a final overview of the results.\n",
    "\n",
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60ef6b-a759-4501-bbab-bf3732c18324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
